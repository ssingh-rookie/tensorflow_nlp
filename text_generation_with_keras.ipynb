{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text generation with keras",
      "provenance": [],
      "authorship_tag": "ABX9TyNfrtxnPRIx3A5Pq5DGH3/A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssingh-rookie/tensorflow_nlp/blob/master/text_generation_with_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0GMODuxGHoG",
        "colab_type": "text"
      },
      "source": [
        "#### Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSkk0k15-aT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afJrq-GjGOkN",
        "colab_type": "text"
      },
      "source": [
        "#### Download and create training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHNv4pJm-f5G",
        "colab_type": "code",
        "outputId": "e6dbb4fb-9e35-446b-beac-8c0592d2b081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = open(path_to_file, 'r').read()\n",
        "vocab = sorted(set(text))\n",
        "print(\"vocab :\", vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n",
            "vocab : ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CLmC6KHAICK",
        "colab_type": "code",
        "outputId": "1ae88122-5f04-44f2-9faa-7c72f5c4e24c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "char_to_index = {char:index for index, char in enumerate(vocab)}\n",
        "index_to_char = np.array(vocab)\n",
        "\n",
        "vocab = sorted(set(text))\n",
        "print(\"vocab :\", vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab : ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8b-UawfCgSH",
        "colab_type": "code",
        "outputId": "138f67f6-1db1-4468-d4ee-31ef72cf1106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "text_as_int = np.array([char_to_index[char] for char in text])\n",
        "text_as_int[:200]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43,\n",
              "       44, 53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39,\n",
              "       52, 63,  1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1,\n",
              "       51, 43,  1, 57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31,\n",
              "       54, 43, 39, 49,  6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56,\n",
              "       57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39,\n",
              "       56, 43,  1, 39, 50, 50,  1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56,\n",
              "       39, 58, 46, 43, 56,  1, 58, 53,  1, 42, 47, 43,  1, 58, 46, 39, 52,\n",
              "        1, 58, 53,  1, 44, 39, 51, 47, 57, 46, 12,  0,  0, 13, 50, 50, 10,\n",
              "        0, 30, 43, 57, 53, 50, 60, 43, 42,  8,  1, 56, 43, 57, 53, 50, 60,\n",
              "       43, 42,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43,\n",
              "       52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63, 53, 59])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6FgnlZmGuaO",
        "colab_type": "text"
      },
      "source": [
        "#### Create training examples and targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE5iplTgEwlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j26PB7guHf2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sedmkMKpIFLC",
        "colab_type": "code",
        "outputId": "ee057c0e-c6d0-4739-84e6-cdea5231885d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[index_to_char[char.numpy()] for char in char_dataset.take(5)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['F', 'i', 'r', 's', 't']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KytsHCahIMk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_RwFROxKa5d",
        "colab_type": "code",
        "outputId": "e24bf857-b1cd-49a9-c34c-d61538c2f03b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "for sequence in sequences.take(3):\n",
        "  print(repr(\" \".join(index_to_char[sequence.numpy()])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'F i r s t   C i t i z e n : \\n B e f o r e   w e   p r o c e e d   a n y   f u r t h e r ,   h e a r   m e   s p e a k . \\n \\n A l l : \\n S p e a k ,   s p e a k . \\n \\n F i r s t   C i t i z e n : \\n Y o u  '\n",
            "'a r e   a l l   r e s o l v e d   r a t h e r   t o   d i e   t h a n   t o   f a m i s h ? \\n \\n A l l : \\n R e s o l v e d .   r e s o l v e d . \\n \\n F i r s t   C i t i z e n : \\n F i r s t ,   y o u   k'\n",
            "\"n o w   C a i u s   M a r c i u s   i s   c h i e f   e n e m y   t o   t h e   p e o p l e . \\n \\n A l l : \\n W e   k n o w ' t ,   w e   k n o w ' t . \\n \\n F i r s t   C i t i z e n : \\n L e t   u s   k i\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTq2yEGoLBSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58879hlCMS1h",
        "colab_type": "code",
        "outputId": "b1f66ab0-18dc-4bd0-fc78-ae25a6da60a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "split_input_target(\"Sundar\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Sunda', 'undar')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voICAfCbMU9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUPnEA9QN75s",
        "colab_type": "code",
        "outputId": "be644308-a801-433b-f2a7-8c6863026ba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "for input, target in dataset.take(5):\n",
        "  print(repr(\" \".join(index_to_char[input.numpy()])))\n",
        "  print(repr(\" \".join(index_to_char[target.numpy()])))\n",
        "  print(\"--------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'F i r s t   C i t i z e n : \\n B e f o r e   w e   p r o c e e d   a n y   f u r t h e r ,   h e a r   m e   s p e a k . \\n \\n A l l : \\n S p e a k ,   s p e a k . \\n \\n F i r s t   C i t i z e n : \\n Y o u'\n",
            "'i r s t   C i t i z e n : \\n B e f o r e   w e   p r o c e e d   a n y   f u r t h e r ,   h e a r   m e   s p e a k . \\n \\n A l l : \\n S p e a k ,   s p e a k . \\n \\n F i r s t   C i t i z e n : \\n Y o u  '\n",
            "--------------------------------------------\n",
            "'a r e   a l l   r e s o l v e d   r a t h e r   t o   d i e   t h a n   t o   f a m i s h ? \\n \\n A l l : \\n R e s o l v e d .   r e s o l v e d . \\n \\n F i r s t   C i t i z e n : \\n F i r s t ,   y o u  '\n",
            "'r e   a l l   r e s o l v e d   r a t h e r   t o   d i e   t h a n   t o   f a m i s h ? \\n \\n A l l : \\n R e s o l v e d .   r e s o l v e d . \\n \\n F i r s t   C i t i z e n : \\n F i r s t ,   y o u   k'\n",
            "--------------------------------------------\n",
            "\"n o w   C a i u s   M a r c i u s   i s   c h i e f   e n e m y   t o   t h e   p e o p l e . \\n \\n A l l : \\n W e   k n o w ' t ,   w e   k n o w ' t . \\n \\n F i r s t   C i t i z e n : \\n L e t   u s   k\"\n",
            "\"o w   C a i u s   M a r c i u s   i s   c h i e f   e n e m y   t o   t h e   p e o p l e . \\n \\n A l l : \\n W e   k n o w ' t ,   w e   k n o w ' t . \\n \\n F i r s t   C i t i z e n : \\n L e t   u s   k i\"\n",
            "--------------------------------------------\n",
            "\"l l   h i m ,   a n d   w e ' l l   h a v e   c o r n   a t   o u r   o w n   p r i c e . \\n I s ' t   a   v e r d i c t ? \\n \\n A l l : \\n N o   m o r e   t a l k i n g   o n ' t ;   l e t   i t   b e  \"\n",
            "\"l   h i m ,   a n d   w e ' l l   h a v e   c o r n   a t   o u r   o w n   p r i c e . \\n I s ' t   a   v e r d i c t ? \\n \\n A l l : \\n N o   m o r e   t a l k i n g   o n ' t ;   l e t   i t   b e   d\"\n",
            "--------------------------------------------\n",
            "'o n e :   a w a y ,   a w a y ! \\n \\n S e c o n d   C i t i z e n : \\n O n e   w o r d ,   g o o d   c i t i z e n s . \\n \\n F i r s t   C i t i z e n : \\n W e   a r e   a c c o u n t e d   p o o r   c i t'\n",
            "'n e :   a w a y ,   a w a y ! \\n \\n S e c o n d   C i t i z e n : \\n O n e   w o r d ,   g o o d   c i t i z e n s . \\n \\n F i r s t   C i t i z e n : \\n W e   a r e   a c c o u n t e d   p o o r   c i t i'\n",
            "--------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98c67Fz6SAd3",
        "colab_type": "text"
      },
      "source": [
        "#### Create training batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L1-CTOKR_1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE=64\n",
        "BUFFER_SIZE = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGib_8JORgbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwoVshBiSU_A",
        "colab_type": "code",
        "outputId": "12d74fdd-304f-4b8b-cd15-3e22c74cd2ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_k3yhRjSis8",
        "colab_type": "text"
      },
      "source": [
        "#### Build The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bsohjamSWGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXhMF7OuT3RL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "                        return_sequences=True,\n",
        "                        stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdRmmd11T798",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG-MD6roUFVh",
        "colab_type": "code",
        "outputId": "c28ce123-b0c7-48be-d0a6-bf9e7b0d9d86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           16640     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 65)            66625     \n",
            "=================================================================\n",
            "Total params: 4,021,569\n",
            "Trainable params: 4,021,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFIvDQSxUoaS",
        "colab_type": "code",
        "outputId": "3d9197bb-abc5-4ee9-d671-5cb9383fdeae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for input_batch_sample, target_batch_sample in dataset.take(1):\n",
        "  example_batch_predictions = model(input_batch_sample)\n",
        "  print(example_batch_predictions.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 65)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81xpNXqMVr8h",
        "colab_type": "code",
        "outputId": "e7b87580-9f25-454f-d7ff-92937c3c3939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "example_batch_predictions[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([100, 65])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzxvZtH4V-5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26jMNisKWY7k",
        "colab_type": "code",
        "outputId": "d6df8d1c-01e6-4499-ace4-9c3e4a9b5cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(repr(\" \".join([index_to_char[index] for index in input_batch_sample[0]])))\n",
        "print(repr(\" \".join([index_to_char[index] for index in sampled_indices])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"  w e l l   p r o c e e d e d , \\n T o   w a r n   f a l s e   t r a i t o r s   f r o m   t h e   l i k e   a t t e m p t s . \\n I   n e v e r   l o o k ' d   f o r   b e t t e r   a t   h i s   h a n\"\n",
            "'J v & m a   x p O d J b F 3 $ U , Z P s J o L \\n . f . b U X G v j c s f D p R   3 B o   K r W O - T c A e o a r V : : S e & K b Y y : Q T M Q j & d z A O I q a z q M B k S Q q 3 G y u H f ? R T ; f V'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "541V0EA2alBU",
        "colab_type": "text"
      },
      "source": [
        "#### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYBJ57JKZgGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNc0QtHncKdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDEx-CVMcObR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSkcNAg2cVwi",
        "colab_type": "code",
        "outputId": "c69506f3-59fc-472d-cee5-23cba0b0d0b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "EPOCHS=10\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 23s 135ms/step - loss: 2.6548\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 23s 136ms/step - loss: 1.9561\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 23s 136ms/step - loss: 1.6897\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 23s 135ms/step - loss: 1.5429\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 23s 135ms/step - loss: 1.4564\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 23s 135ms/step - loss: 1.3957\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 23s 134ms/step - loss: 1.3513\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 23s 134ms/step - loss: 1.3120\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 23s 134ms/step - loss: 1.2778\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 23s 135ms/step - loss: 1.2458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOJQMEKDcr-1",
        "colab_type": "code",
        "outputId": "12d61754-fbd6-4ee2-d44a-f55b9ee829c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./training_checkpoints/ckpt_10'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiliWha5eBHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd-tosu8eLFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 1000\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char_to_index[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 0.5\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(index_to_char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niIOuGVtevJ0",
        "colab_type": "code",
        "outputId": "538504fc-f027-440e-b160-cc633da38dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "print(generate_text(model, start_string=u\"JULIET: \"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "JULIET: that which I but believe not your lady:\n",
            "For this way, and you shall be the vein of them.\n",
            "\n",
            "CAMILLO:\n",
            "I do not stand and will be company:\n",
            "There is no with the fire, the time would set down the county\n",
            "But that hath promised me in the world.\n",
            "\n",
            "KING RICHARD III:\n",
            "Stand, and do you good nor good to the duke\n",
            "What is the precious lord?\n",
            "\n",
            "KING RICHARD III:\n",
            "Came to the lady, my must not know\n",
            "That which the deed is worthy father, he is had done with him.\n",
            "\n",
            "CAPULET:\n",
            "How shall I be gone, so stay and with the very house.\n",
            "\n",
            "Third Citizen:\n",
            "Your mother was the battle let thy brother did the blood\n",
            "With the heavens have brought you for the court.\n",
            "\n",
            "CORIOLANUS:\n",
            "I have spoke of all that hath company.\n",
            "\n",
            "KING RICHARD III:\n",
            "Son, I think there which is the worst; he is in your blows,\n",
            "For this is the direct of my lord, he was she would do you shall stook and welcome.\n",
            "\n",
            "MENENIUS:\n",
            "I will show the duke, which is the way;\n",
            "That shall be some mighty soul to death,\n",
            "When we more death,\n",
            "That she will sting the charity of place, w\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jyaab1oDfLHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}